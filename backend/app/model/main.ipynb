{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c186539-5a58-441c-b078-ab21c00686ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f56a04-e0ba-4e43-a3f9-1fba170af5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightning\n",
    "%pip install torchvision\n",
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d354a-9271-4864-83ee-9b1c7b1a771d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5d5c5-f775-474e-a74a-71207e63ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import os\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e66fab-bff6-4689-ac55-394d225454c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43410e76-bc04-4a1c-a85a-777274600ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = ('cel', 'cla', 'flu', 'gac', 'gel', 'org',\n",
    "                'pia', 'sax', 'tru', 'vio', 'voi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94080f-f2b3-4448-9415-45da2e596833",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b889e5-b733-408a-b837-7e282a27f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    '''Dataset for loading given training examples - examples for each label\n",
    "    are stored in separate directory'''\n",
    "    def __init__(self, source_dir: str):\n",
    "        self.class_dir_paths = [os.path.join(source_dir, c)\n",
    "                                for c in CLASS_LABELS]\n",
    "        self.class_dirs = [[os.path.join(c_path, f)\n",
    "                            for f in os.listdir(c_path)]\n",
    "                           for c_path in self.class_dir_paths]\n",
    "        self.class_sizes = [len(c_dir) for c_dir in self.class_dirs]\n",
    "        self.size = sum(self.class_sizes)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        if idx >= self.size:\n",
    "            raise IndexError('Item index out of range!')\n",
    "\n",
    "        file_idx = idx\n",
    "        for class_idx in range(len(CLASS_LABELS)):\n",
    "            if file_idx < self.class_sizes[class_idx]:\n",
    "                break\n",
    "            else:\n",
    "                file_idx -= self.class_sizes[class_idx]\n",
    "\n",
    "        data = torch.load(self.class_dirs[class_idx][file_idx])\n",
    "        data.requires_grad = False\n",
    "        return data, torch.Tensor([1 if i == class_idx else 0 for i in range(len(CLASS_LABELS))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b65e9-1884-458e-b6ff-0c677feb6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    '''Dataset that loads examples and labels stored as tensor files in\n",
    "    source_dir. Each pair (example, label) is stored as a single .pt file'''\n",
    "    def __init__(self, source_dir: str):\n",
    "        self.files = [os.path.join(source_dir, f) for f in os.listdir(source_dir)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        data, label = torch.load(self.files[idx])\n",
    "        data.requires_grad = False\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f8e98-5094-406e-b369-2d42a3881a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache(Dataset):\n",
    "    def __init__(self, source_dataset: Dataset,\n",
    "                 calculate_label_distributions: bool = False):\n",
    "        self.data = []\n",
    "        if calculate_label_distributions:\n",
    "            label_sum = torch.zeros((len(CLASS_LABELS)))\n",
    "            for i in range(len(source_dataset)):\n",
    "                example, label = source_dataset[i]\n",
    "                label_sum += label\n",
    "                self.data.append((example, label))\n",
    "            self.label_distributions = label_sum / len(source_dataset)\n",
    "        else:\n",
    "            self.label_distributions = None\n",
    "            for i in range(len(source_dataset)):\n",
    "                self.data.append(source_dataset[i])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42228fd3-1a19-4515-b715-b1564f57a38a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1a065-e508-4d32-ab08-c56583bb966f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8cb00-64cd-4204-b87c-eab8d4263b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBCELoss(nn.Module):\n",
    "    '''Binary Cross Entropy that takes into account within-label imbalances'''\n",
    "    def __init__(self, label_distribution, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.fn_weights = 1 - label_distribution\n",
    "        self.fp_weights = label_distribution\n",
    "        self.bce_loss = nn.BCELoss(reduction='none')\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = self.bce_loss(input, target)\n",
    "        fn_loss = loss * self.fn_weights * target\n",
    "        fp_loss = loss * self.fp_weights * (1 - target)\n",
    "        loss = fn_loss + fp_loss\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f427319-7070-4bb4-88d5-0df9c1b7588e",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37824f5a-09ce-4317-819a-46774a293c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastLayer(pl.LightningModule):\n",
    "    def __init__(self, loss: nn.Module, num_features: int = 2048,\n",
    "                 num_labels: int = len(CLASS_LABELS),\n",
    "                 learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fc = nn.Linear(num_features, num_labels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.metrics = {\n",
    "            'loss': loss,\n",
    "            'accuracy': torchmetrics.Accuracy(task='multilabel',\n",
    "                                              num_labels=num_labels),\n",
    "            'precision': torchmetrics.Precision(task=\"multilabel\",\n",
    "                                                num_labels=num_labels),\n",
    "            'recall': torchmetrics.Recall(task='multilabel',\n",
    "                                          num_labels=num_labels),\n",
    "            'hamming_distance': torchmetrics.HammingDistance(task='multilabel',\n",
    "                                                             num_labels=num_labels)\n",
    "        }\n",
    "\n",
    "    def _get_metrics(self, preds, target, label):\n",
    "        metrics = {}\n",
    "        for k, v in self.metrics.items():\n",
    "            metrics[label+'_'+k] = v(preds, target)\n",
    "        return metrics\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        metrics = self._get_metrics(y_hat, y, 'train')\n",
    "        self.log_dict(metrics, on_step=False, on_epoch=True)\n",
    "\n",
    "        return metrics['train_loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        metrics = self._get_metrics(y_hat, y, 'validation')\n",
    "        self.log_dict(metrics, on_step=False, on_epoch=True)\n",
    "\n",
    "        return metrics['validation_loss']\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        metrics = self._get_metrics(y_hat, y, 'test')\n",
    "        self.log_dict(metrics, on_step=False, on_epoch=True)\n",
    "\n",
    "        return metrics['test_loss']\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.fc.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736ac69-fcbc-4aa3-a544-39fd21dfa234",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bfb5a-dab9-4a2f-99ff-d14ca6da8d16",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901633f-20cc-4bb6-8b24-5a86cec6c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the following paths according to output paths used in preprocessing.ipynb\n",
    "DATASET_ROOT_DIR = input('Dataset root directory: ') or '/home/studio-lab-user/Dataset'\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATASET_ROOT_DIR, 'melspec_resnet50_training')\n",
    "TRAIN_DIR_MIX_2 = os.path.join(DATASET_ROOT_DIR, 'melspec_resnet50_training_mix_2')\n",
    "TRAIN_DIR_MIX_3 = os.path.join(DATASET_ROOT_DIR, 'melspec_resnet50_training_mix_3')\n",
    "VAL_DIR = os.path.join(DATASET_ROOT_DIR, 'melspec_resnet50_validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a060837d-0f8a-49b7-b17e-62a6297b9a02",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973adb30-a818-4079-9dc3-7d3c7c19a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_raw = TrainingDataset(TRAIN_DIR)\n",
    "ds_train_mix_2 = TensorDataset(TRAIN_DIR_MIX_2)\n",
    "ds_train_mix_3 = TensorDataset(TRAIN_DIR_MIX_3)\n",
    "ds_train = Cache(source_dataset=ConcatDataset((ds_train_raw, ds_train_mix_2,\n",
    "                                               ds_train_mix_3)),\n",
    "                 calculate_label_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff1f6be-a680-4b94-938d-5b140d60e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Label distribution on training data:')\n",
    "print(ds_train.label_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d6735-29e3-4430-9858-8edbf7e14161",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_provided_validation = Cache(source_dataset=TensorDataset(VAL_DIR),\n",
    "                               calculate_label_distributions=True)\n",
    "print('Label distribution on provided validation data:')\n",
    "print(ds_provided_validation.label_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6d5f0-d955-4372-a0ea-c0ef4690b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_train\n",
    "ds_train, ds_validation = torch.utils.data.random_split(ds, (0.85, 0.15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5634a-3678-4100-83d2-3ed2e2bf6ce8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf4e26-759f-49b0-8b78-efd689abcf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to ds_provided_validation.label_distributions if you want to adjust\n",
    "# loss according to provided validation data instead of our training data\n",
    "loss = WeightedBCELoss(ds.label_distributions)\n",
    "# uncomment if you want to use the default BCELoss\n",
    "# loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18730849-782e-43ea-9eca-e452578d4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=64,\n",
    "                                           shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(ds_validation, batch_size=64,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "\n",
    "model = LastLayer(loss=loss, num_features=2048)\n",
    "model_label = input('Model label (for tensorboard graphs): ')\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), name='lightning_logs',\n",
    "                           version=model_label)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=22, logger=logger)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
