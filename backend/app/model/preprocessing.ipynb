{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94413c37",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9c9d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543edc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc624cb9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ede868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import random\n",
    "from typing import Callable\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df13b2-b073-4c0c-998b-4eeb27090649",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea899a7-46d1-4031-b6be-a5d40107ade0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = input('Dataset path: ') or 'Dataset/'\n",
    "TRAINING_DATASET_PATH = DATASET_PATH + 'IRMAS_Training_Data/'\n",
    "VALIDATION_DATASET_PATH = DATASET_PATH + 'IRMAS_Validation_Data/'\n",
    "\n",
    "CLASSES = (\n",
    "    'cel',\n",
    "    'cla',\n",
    "    'flu',\n",
    "    'gac',\n",
    "    'gel',\n",
    "    'org',\n",
    "    'pia',\n",
    "    'sax',\n",
    "    'tru',\n",
    "    'vio',\n",
    "    'voi'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4001d-cdeb-4a6f-9079-237b7b832cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cddfaa0-1e1f-4d16-b7c7-63130477d43c",
   "metadata": {},
   "source": [
    "### Transform existing data (without mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9e863-b510-44be-ac86-46187e850b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_training_data(output_dir: str, transform: Callable,\n",
    "                            source_dir: str = TRAINING_DATASET_PATH) -> None:\n",
    "    '''`transform` should be a callable that accepts signal and sample rate and\n",
    "    returns torch.Tensor'''\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    for c in CLASSES:\n",
    "        output_path = os.path.join(output_dir, c)\n",
    "        if not os.path.isdir(output_path):\n",
    "            os.mkdir(output_path)\n",
    "\n",
    "        for f in os.scandir(os.path.join(source_dir, c)):\n",
    "            name, ext = os.path.splitext(f.path)\n",
    "            if ext == '.wav':\n",
    "                signal, sample_rate = lr.load(f.path)\n",
    "                result = transform(signal, sample_rate)\n",
    "                output_filename = os.path.splitext(f.name)[0] + '.pt'\n",
    "                output_filepath = os.path.join(output_path, output_filename)\n",
    "                torch.save(result, output_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b993b1-bfca-432d-8fd9-71e889484717",
   "metadata": {},
   "source": [
    "### Mix training examples and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d1df8-cbb7-4f33-afc7-5c3748facaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_and_transform(output_dir: str, transform: Callable,\n",
    "                      mix_together: int, num_examples: int,\n",
    "                      source_dir: str = TRAINING_DATASET_PATH) -> None:\n",
    "    '''Mix together training examples and perform transform.\n",
    "    mix_together param tells how many input examples will be included in the\n",
    "    mix.'''\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    class_dir_paths = [os.path.join(source_dir, c) for c in CLASSES]\n",
    "    class_dirs = [[os.path.join(c_path, f) for f in os.listdir(c_path)]\n",
    "                  for c_path in class_dir_paths]\n",
    "    digits = len(str(num_examples-1))\n",
    "\n",
    "    label_combinations = list(combinations(range(len(CLASSES)), mix_together))\n",
    "    past_combinations = [set() for c in label_combinations]\n",
    "\n",
    "    num_combinations = len(label_combinations)\n",
    "    for i in range(num_examples):\n",
    "        combination_idx = i % num_combinations\n",
    "        combination = label_combinations[combination_idx]\n",
    "        sources = []\n",
    "        for label in combination:\n",
    "            sources.append(random.choice(class_dirs[label]))\n",
    "        # ensure we don't generate duplicates\n",
    "        while tuple(sources) in past_combinations[combination_idx]:\n",
    "            sources = []\n",
    "            for label in combination:\n",
    "                sources.append(random.choice(class_dirs[label]))\n",
    "        past_combinations[combination_idx].add(tuple(sources))\n",
    "\n",
    "        # load the source examples\n",
    "        signal, sample_rate = lr.load(sources[0])\n",
    "        for filename in sources[1:]:\n",
    "            source_signal, _ = lr.load(filename)\n",
    "            signal += source_signal\n",
    "\n",
    "        data = transform(signal, sample_rate)\n",
    "        labels = torch.Tensor([1 if i in combination else 0 for i in\n",
    "                               range(len(CLASSES))])\n",
    "        torch.save((data, labels), os.path.join(output_dir,\n",
    "                                                f'{i:0{digits}}.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782a4be-4c13-4ddc-ba0f-77318134742a",
   "metadata": {},
   "source": [
    "## Transform validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9e30c-e9ee-4245-a7a2-7fe2ad35430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_validation_labels(filename: str) -> torch.Tensor:\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.rstrip() for line in f.readlines()]\n",
    "    labels = torch.Tensor([1 if c in lines else 0 for c in CLASSES])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9631977-bf82-4800-91f6-9baa7c9428ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_validation_data(output_dir: str, transform: Callable,\n",
    "                              source_dir: str = VALIDATION_DATASET_PATH):\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    files_split = [os.path.splitext(f.name) for f in os.scandir(source_dir)]\n",
    "    file_names = [f[0] for f in files_split if f[1] == '.wav']\n",
    "    for filename in file_names:\n",
    "        wav_file = filename + '.wav'\n",
    "        label_file = filename + '.txt'\n",
    "\n",
    "        signal, sample_rate = lr.load(os.path.join(source_dir, wav_file))\n",
    "        data = transform(signal, sample_rate)\n",
    "        labels = read_validation_labels(os.path.join(source_dir, label_file))\n",
    "\n",
    "        torch.save((data, labels), os.path.join(output_dir, filename+'pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64ed97-f566-473a-95ef-c9119433bcd0",
   "metadata": {},
   "source": [
    "## ResNet50 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecb1ce-0b7e-4bb0-9bf7-bb4826def0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspec_resnet50_transform_factory(hop_length: int = 256,\n",
    "                                       n_mels: int = 256) -> Callable:\n",
    "    resnet49 = models.resnet50(weights='DEFAULT')\n",
    "\n",
    "    resnet49.fc = torch.nn.Identity()\n",
    "\n",
    "    def melspec_resnet50_transform(signal: np.ndarray, sample_rate: int)\\\n",
    "            -> torch.Tensor:\n",
    "        melspec = torch.Tensor(lr.feature.melspectrogram(y=signal,\n",
    "                                                         sr=sample_rate,\n",
    "                                                         hop_length=hop_length,\n",
    "                                                         n_mels=n_mels))\n",
    "        normalized = (melspec - torch.min(melspec)) /\\\n",
    "                     (torch.max(melspec) - torch.min(melspec))\n",
    "        tripled = torch.stack((normalized, normalized, normalized), axis=0)\n",
    "        resnet_features = resnet49(torch.unsqueeze(tripled, dim=0))\n",
    "        return torch.squeeze(resnet_features, dim=0)\n",
    "    return melspec_resnet50_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f58410-4b63-4bb9-8c05-d74dcb0264ea",
   "metadata": {},
   "source": [
    "### ResNet50 training transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4ecf2-671d-45fd-9723-1b9d98bb31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_resnet50_training_output = os.path.join(DATASET_PATH, 'melspec_resnet50_training/')\n",
    "transform_training_data(melspec_resnet50_training_output, melspec_resnet50_transform_factory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb24d45-0593-4b16-8b06-1bdce0bb0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_resnet50_training_output_mix2 = os.path.join(DATASET_PATH, 'melspec_resnet50_training_mix_2/')\n",
    "mix_and_transform(melspec_resnet50_training_output_mix2,\n",
    "                  melspec_resnet50_transform_factory(), mix_together=2,\n",
    "                  num_examples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058077e8-c132-49ff-a4d3-2117a58afee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_resnet50_training_output_mix3 = os.path.join(DATASET_PATH, 'melspec_resnet50_training_mix_3/')\n",
    "mix_and_transform(melspec_resnet50_training_output_mix3,\n",
    "                  melspec_resnet50_transform_factory(), mix_together=3,\n",
    "                  num_examples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345f4e3-5fc7-419f-864e-b456ebf238de",
   "metadata": {},
   "source": [
    "### ResNet50 validation transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0241d1b-be26-4cb1-8017-88245c2cc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_resnet50_validation_output = os.path.join(DATASET_PATH, 'melspec_resnet50_validation/')\n",
    "transform_validation_data(melspec_resnet50_validation_output,\n",
    "                          melspec_resnet50_transform_factory())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee221b7-9f89-42ec-8d7f-0afb8f616a8d",
   "metadata": {},
   "source": [
    "## Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fcd60-ee4d-4ec8-95e6-ddc369215b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def melspec_transform_factory(hop_length: int = 256, n_mels: int = 256)\\\n",
    "        -> Callable:\n",
    "    def melspec_transform(signal: np.ndarray, sample_rate: int)\\\n",
    "            -> torch.Tensor:\n",
    "        return torch.Tensor(lr.feature.melspectrogram(y=signal, sr=sample_rate,\n",
    "                                                      hop_length=hop_length,\n",
    "                                                      n_mels=n_mels))\n",
    "    return melspec_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f1598-e184-4307-8807-00a17f3e5685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "melspec_output = os.path.join(DATASET_PATH, 'melspec_training/')\n",
    "transform_training_data(melspec_output, melspec_transform_factory())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
